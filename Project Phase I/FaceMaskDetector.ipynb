{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "IrM2eLM0jw_n"
   },
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data import RandomSampler\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
    "from torch import Tensor\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-8A8p2UskMzF"
   },
   "outputs": [],
   "source": [
    "# Path of training and testing dataset\n",
    "DIR_TRAIN = \"C:\\\\Users\\\\yasht\\\\OneDrive\\\\Desktop\\\\Study\\\\AI\\\\Assignments\\\\AI Project Phase I\\\\TRAIN\"\n",
    "\n",
    "#DIR_TEST = \"C:\\\\Users\\\\Yashvi\\\\Downloads\\\\Dataset-20220607T040852Z-001\\\\Dataset\\\\TEST\"\n",
    "#DIR_TRAIN = \"C:\\\\Users\\\\Yashvi\\\\Downloads\\\\Dataset-20220607T040852Z-001\\\\Dataset\\\\TRAIN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "l0WcAQ_skUV_"
   },
   "outputs": [],
   "source": [
    "# Labels (classes) to differentiate the images in these categories\n",
    "label_dict = {\n",
    "    0: \"Person with Cloth Mask\", \n",
    "    1: \"Person with FFP2 Mask\", \n",
    "    2: \"Person with Surgical Mask\",\n",
    "    3: \"Person without Mask\",\n",
    "    4: \"Person with incorrect Mask\"\n",
    "}\n",
    "\n",
    "# Labels to display on the confussion matrix\n",
    "labels_list = [\"Person with Cloth Mask\",\"Person with FFP2 Mask\",\"Person with Surgical Mask\",\"Person without Mask\",\"Person with incorrect Mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vjTfA0QpkWyA",
    "outputId": "9ac27592-67c4-4084-f410-3dae4ad68241"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Classes:  5 \n",
      "\n",
      "Cloth :  650\n",
      "FFP2 :  650\n",
      "Incorrect :  650\n",
      "NoMask :  650\n",
      "Surgical :  650\n",
      "\n",
      "\n",
      "Total :  3250 \n",
      "\n",
      "Total Classes:  5 \n",
      "\n",
      "Cloth :  650\n",
      "FFP2 :  650\n",
      "Incorrect :  650\n",
      "NoMask :  650\n",
      "Surgical :  650\n",
      "\n",
      "\n",
      "Total :  3250 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Displaying total images in each class and total number of images overall\n",
    "classes = os.listdir(DIR_TRAIN)\n",
    "print(\"Total Classes: \",len(classes),\"\\n\")\n",
    "#Counting total images in each class\n",
    "\n",
    "total = 0\n",
    "individual_count = []\n",
    "for _class in classes:\n",
    "    individual_count.append(len(os.listdir(DIR_TRAIN +\"/\"+_class)))\n",
    "    total += len(os.listdir(DIR_TRAIN + \"/\"+_class))\n",
    "\n",
    "for i in range(0,len(individual_count)):\n",
    "  print(classes[i],\": \", individual_count[i])\n",
    "print(\"\\n\")\n",
    "print(\"Total : \", total, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "iZNd1uAWkZ-Y"
   },
   "outputs": [],
   "source": [
    "train_imgs = []\n",
    "test_imgs = []\n",
    "\n",
    "for _class in classes:\n",
    "    \n",
    "    for img in os.listdir(DIR_TRAIN +\"/\"+ _class):\n",
    "        train_imgs.append(DIR_TRAIN + _class + \"/\" + img)\n",
    "        \n",
    "\n",
    "class_to_int = {classes[i] : i for i in range(len(classes))}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tDHoW1Rnkeen"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2370\n",
      "790\n",
      "2370\n",
      "790\n"
     ]
    }
   ],
   "source": [
    "#Loading Classification Dataset\n",
    "\n",
    "\n",
    "transform = T.Compose([T.Resize((224,224)),\n",
    "                                T.ToTensor()])\n",
    "\n",
    "#training_data = ImageFolder(root = DIR_TRAIN, transform = transform)\n",
    "#testing_data = ImageFolder(root = DIR_TEST, transform = transform)\n",
    "\n",
    "train_dataset = ImageFolder(root = DIR_TRAIN, transform = transform)\n",
    "dataset = len(train_dataset)\n",
    "training_data, testing_data = torch.utils.data.random_split(train_dataset, [dataset-int(0.25*dataset) , int(0.25*dataset)])\n",
    "\n",
    "\n",
    "\n",
    "#Data Loader\n",
    "train_random_sampler = RandomSampler(training_data)\n",
    "test_random_sampler = RandomSampler(testing_data)\n",
    "\n",
    "\n",
    "train_data_loader = DataLoader(\n",
    "    dataset = training_data,\n",
    "    batch_size = 16,\n",
    "    num_workers = 4,\n",
    "    shuffle= True\n",
    ")\n",
    "\n",
    "\n",
    "test_data_loader = DataLoader(\n",
    "    dataset = testing_data,\n",
    "    batch_size = 16,\n",
    "    num_workers = 4,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(len(training_data))\n",
    "print(len(testing_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "5Wnl11KIkn8F"
   },
   "outputs": [],
   "source": [
    "class MaskDetect(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            # convolution layer 1\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # convolution layer 2\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # convolution layer 3\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear(200704, 5)\n",
    "        )\n",
    "\n",
    "    # forward pass to readjust weights\n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        #         print(x.size())\n",
    "        x = self.linear_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "RS7bx1J6kqyD"
   },
   "outputs": [],
   "source": [
    "#Get device\n",
    "model = MaskDetect()\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "#Training Details\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.75)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_loss = []\n",
    "train_accuracy = []\n",
    "\n",
    "\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "TnCtY7-klOu3"
   },
   "outputs": [],
   "source": [
    "#Defining function of accuracy calculation\n",
    "def calc_accuracy(true,pred):\n",
    "    pred = F.softmax(pred, dim = 1)\n",
    "    true = torch.zeros(pred.shape[0], pred.shape[1]).scatter_(1, true.unsqueeze(1), 1.)\n",
    "    acc = (true.argmax(-1) == pred.argmax(-1)).float().detach().numpy()\n",
    "    acc = float((100 * acc.sum()) / len(acc))\n",
    "    return round(acc, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eh6jJalslQlW",
    "outputId": "7762756f-5fc3-44a5-e5b6-a3e64db52bc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Iteration 100 < \n",
      "Iter Loss = 4.5217\n",
      "Iter Accuracy = 50.0 % \n",
      "\n",
      "> Iteration 100 < \n",
      "Iter Loss = 4.5217\n",
      "Iter Accuracy = 50.0 % \n",
      "\n",
      "** Epoch 1 ** - Epoch Time 745\n",
      "Train Loss = 26.8368\n",
      "** Epoch 1 ** - Epoch Time 745\n",
      "Train Loss = 26.8368\n",
      "> Iteration 100 < \n",
      "Iter Loss = 1.8684\n",
      "Iter Accuracy = 56.25 % \n",
      "\n",
      "> Iteration 100 < \n",
      "Iter Loss = 1.8684\n",
      "Iter Accuracy = 56.25 % \n",
      "\n",
      "** Epoch 2 ** - Epoch Time 760\n",
      "Train Loss = 2.4029\n",
      "** Epoch 2 ** - Epoch Time 760\n",
      "Train Loss = 2.4029\n"
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "\n",
    "testing_accuracy = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()    \n",
    "    start = time.time()\n",
    "    \n",
    "    #Epoch Loss & Accuracy\n",
    "    train_epoch_loss = []\n",
    "    train_epoch_accuracy = []\n",
    "    _iter = 1\n",
    "    \n",
    "    #Training\n",
    "    for images, labels in train_data_loader:\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        #Reset Grads\n",
    "        optimizer.zero_grad()\n",
    "  \n",
    "        #Forward ->\n",
    "        preds = model(images)\n",
    "        \n",
    "        #Calculate Accuracy\n",
    "        acc = calc_accuracy(labels.cpu(), preds.cpu())\n",
    "        \n",
    "        #Calculate Loss & Backward, Update Weights (Step)\n",
    "        loss = criterion(preds, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #Append loss & accuracy\n",
    "        loss_value = loss.item()\n",
    "        train_epoch_loss.append(loss_value)\n",
    "        train_epoch_accuracy.append(acc)\n",
    "        \n",
    "        if _iter % 100 == 0:\n",
    "            print(\"> Iteration {} < \".format(_iter))\n",
    "            print(\"Iter Loss = {}\".format(round(loss_value, 4)))\n",
    "            print(\"Iter Accuracy = {} % \\n\".format(acc))\n",
    "        \n",
    "        _iter += 1\n",
    "\n",
    "    end = time.time()\n",
    "    \n",
    "    train_epoch_loss = np.mean(train_epoch_loss)\n",
    "    train_epoch_accuracy = np.mean(train_epoch_accuracy)\n",
    "    train_loss.append(train_epoch_loss)\n",
    "    train_accuracy.append(train_epoch_accuracy)\n",
    "    \n",
    "    #Print Epoch Statistics\n",
    "    print(\"** Epoch {} ** - Epoch Time {}\".format(epoch+1, int(end-start)))\n",
    "    print(\"Train Loss = {}\".format(round(train_epoch_loss, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8V3jGP8SvMiz"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"C:\\\\Users\\\\Yashvi\\\\Desktop\\\\AI\\\\AI PROJECT I\\\\Dataset\\\\Trained_Model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "mLBJf5GvlgsE",
    "outputId": "e7eea3f0-c419-4251-cc25-f3c1552512f6"
   },
   "outputs": [],
   "source": [
    "plt.plot(train_loss, label='Training loss')\n",
    "plt.title('Loss at the end of each epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 672
    },
    "id": "PoEULAPTtH_p",
    "outputId": "2f287c25-e9cb-44d7-9382-a277c471b201"
   },
   "outputs": [],
   "source": [
    "#Testing the model\n",
    "testing_accuracy = []\n",
    "predictions_list = []\n",
    "accurate_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "  for images, labels in test_data_loader:      \n",
    "        model.eval()\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        _, pred_values = torch.max(model(images), dim=1)\n",
    "        predictions_list.extend(pred_values.detach().cpu().numpy())\n",
    "        accurate_list.extend(labels.detach().cpu().numpy())\n",
    "        #Forward ->\n",
    "        preds = model(images)\n",
    "        #Calculate Accuracy\n",
    "        acc = calc_accuracy(labels.cpu(), preds.cpu())\n",
    "        testing_accuracy.append(acc);\n",
    "\n",
    "print(\"Final Accuracy: \", np.mean(testing_accuracy),\"\\n\")\n",
    "print(\"Testing Classification Report\")\n",
    "print(classification_report(accurate_list, predictions_list),\"\\n\")\n",
    "print(\"Confusion Matrix:\")\n",
    "# plt.figure()\n",
    "confusion_matrix_instance = confusion_matrix(accurate_list, predictions_list)\n",
    "plt.imshow(confusion_matrix_instance, interpolation='nearest', cmap=plt.cm.Pastel2)\n",
    "for (x_cordinate, y_cordinate), val in np.ndenumerate(confusion_matrix_instance):\n",
    "    plt.text(x_cordinate, y_cordinate, val, ha='center', va='center')\n",
    "plt.title('Testing Confusion matrix')\n",
    "plt.ylabel('Actual labels')\n",
    "plt.xlabel('Predicted labels')\n",
    "randomized_val = np.arange(len(labels_list))\n",
    "plt.xticks(randomized_val, labels_list, rotation=60)\n",
    "plt.yticks(randomized_val, labels_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S9TZFG9NtOHz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FaceMaskDetector.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
